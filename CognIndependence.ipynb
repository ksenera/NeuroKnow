{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b190174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NeuroKnow: AI-Powered Learning Optimization for Neurodivergent Students\n",
    "# Comprehensive Model Comparison Study\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f07f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Introduction\n",
    "print(\"\"\"\n",
    "# NeuroKnow: AI-Powered Learning Optimization for Neurodivergent Students\n",
    "## Predicting Optimal Learning Modalities Using Machine Learning\n",
    "\n",
    "**Abstract** - This study compares multiple machine learning algorithms to identify the best model \n",
    "for predicting optimal learning pathways for neurodivergent students. By analyzing cognitive profiles, \n",
    "learning patterns, and performance data, we aim to create personalized educational recommendations \n",
    "that maximize learning efficiency and knowledge retention. The project evaluates eight different \n",
    "algorithms using cross-validation and ROC-AUC analysis to determine the most effective approach \n",
    "for educational personalization.\n",
    "\n",
    "**Keywords** - neurodivergent learning, educational AI, personalized learning, cognitive profiling, \n",
    "machine learning, cross-validation, ROC analysis, modality optimization\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0756f81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Generate Synthetic Cognitive Dataset\n",
    "def generate_neurodivergent_dataset(n_samples=1000):\n",
    "    \"\"\"Generate synthetic dataset representing neurodivergent learning profiles\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    data = {\n",
    "        'age': np.random.randint(8, 18, n_samples),\n",
    "        'attention_span': np.random.normal(25, 10, n_samples),  # minutes\n",
    "        'working_memory': np.random.normal(6, 2, n_samples),    # digit span\n",
    "        'processing_speed': np.random.normal(85, 15, n_samples), # standardized score\n",
    "        'visual_learning_score': np.random.normal(70, 20, n_samples),\n",
    "        'auditory_learning_score': np.random.normal(65, 18, n_samples),\n",
    "        'kinesthetic_learning_score': np.random.normal(75, 22, n_samples),\n",
    "        'logical_reasoning_score': np.random.normal(80, 15, n_samples),\n",
    "        'error_recovery_rate': np.random.normal(0.6, 0.2, n_samples), # 0-1 scale\n",
    "        'abstraction_ability': np.random.normal(70, 18, n_samples),\n",
    "        'previous_success_rate': np.random.normal(0.7, 0.15, n_samples)\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Create target variable: optimal learning modality (0: Visual, 1: Auditory, 2: Kinesthetic, 3: Logical)\n",
    "    # Based on highest learning score with some noise\n",
    "    scores = df[['visual_learning_score', 'auditory_learning_score', \n",
    "                 'kinesthetic_learning_score', 'logical_reasoning_score']].values\n",
    "    optimal_modality = np.argmax(scores, axis=1)\n",
    "\n",
    "    # Add some realistic noise\n",
    "    noise = np.random.choice([-1, 0, 1], size=n_samples, p=[0.1, 0.8, 0.1])\n",
    "    df['optimal_modality'] = (optimal_modality + noise) % 4\n",
    "\n",
    "    # Add some missing values realistically (5% missing)\n",
    "    for col in ['working_memory', 'processing_speed', 'error_recovery_rate']:\n",
    "        mask = np.random.random(n_samples) < 0.05\n",
    "        df.loc[mask, col] = np.nan\n",
    "\n",
    "    return df\n",
    "\n",
    "# Generate and display dataset\n",
    "cognitive_df = generate_neurodivergent_dataset()\n",
    "print(\"Dataset Overview:\")\n",
    "print(f\"Shape: {cognitive_df.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(cognitive_df.head())\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "cognitive_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fbb385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Data Cleaning and Exploration\n",
    "def handle_missing_data(df, strategy='mean'):\n",
    "    \"\"\"Handle missing values using specified strategy\"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    if strategy == 'mean':\n",
    "        # Fill numerical columns with mean\n",
    "        numerical_cols = ['working_memory', 'processing_speed', 'error_recovery_rate']\n",
    "        for col in numerical_cols:\n",
    "            df_clean[col].fillna(df_clean[col].mean(), inplace=True)\n",
    "    else:  # drop\n",
    "        df_clean = df_clean.dropna()\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Create two datasets for comparison\n",
    "df_mean_filled = handle_missing_data(cognitive_df, 'mean')\n",
    "df_dropped = handle_missing_data(cognitive_df, 'drop')\n",
    "\n",
    "print(\"Dataset sizes after preprocessing:\")\n",
    "print(f\"Mean-filled: {df_mean_filled.shape}\")\n",
    "print(f\"Dropped missing: {df_dropped.shape}\")\n",
    "\n",
    "# Visualize the distribution of optimal modalities\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "modality_names = ['Visual', 'Auditory', 'Kinesthetic', 'Logical']\n",
    "df_mean_filled['optimal_modality'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('Optimal Modality Distribution (Mean-filled)')\n",
    "plt.xticks(ticks=range(4), labels=modality_names, rotation=45)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "df_dropped['optimal_modality'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('Optimal Modality Distribution (Dropped)')\n",
    "plt.xticks(ticks=range(4), labels=modality_names, rotation=45)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d90633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Model Initialization and Configuration\n",
    "class NeurodivergentModelComparator:\n",
    "    def __init__(self):\n",
    "        self.models = {\n",
    "            'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "            'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            'SVM Linear': SVC(kernel='linear', probability=True, random_state=42),\n",
    "            'SVM RBF': SVC(kernel='rbf', probability=True, random_state=42),\n",
    "            'SVM Poly': SVC(kernel='poly', probability=True, random_state=42),\n",
    "            'SVM Sigmoid': SVC(kernel='sigmoid', probability=True, random_state=42),\n",
    "            'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "            'Naive Bayes': GaussianNB(),\n",
    "            'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "            'Neural Network': MLPClassifier(hidden_layer_sizes=(100, 50), random_state=42, max_iter=1000)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236ffc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: ROC Curve Analysis\n",
    "def plot_roc_curves(results_summary, dataset_name):\n",
    "    \"\"\"Plot ROC curves for all models on specified dataset\"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    results = results_summary[dataset_name]\n",
    "    \n",
    "    for model_name, model_results in results.items():\n",
    "        if model_results is not None:\n",
    "            # For multi-class, we plot each class separately or use micro-average\n",
    "            y_test = model_results['y_test']\n",
    "            y_pred_proba = model_results['y_pred_proba']\n",
    "            \n",
    "            # Compute micro-average ROC curve and ROC area\n",
    "            fpr, tpr, _ = roc_curve(y_test.ravel(), y_pred_proba.ravel())\n",
    "            roc_auc = model_results['roc_auc']\n",
    "            \n",
    "            plt.plot(fpr, tpr, lw=2, \n",
    "                    label=f'{model_name} (AUC = {roc_auc:.3f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', alpha=0.5)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curves - {dataset_name} Dataset\\n(Multi-class Micro-average)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Plot ROC curves for both datasets\n",
    "for dataset_name in ['Mean_Filled', 'Dropped']:\n",
    "    plot_roc_curves(results_summary, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74457621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Identify Best Performing Model\n",
    "def find_best_model(results_summary):\n",
    "    \"\"\"Identify the best model based on multiple metrics\"\"\"\n",
    "    \n",
    "    best_models = {}\n",
    "    \n",
    "    for dataset_name, results in results_summary.items():\n",
    "        # Filter out failed models\n",
    "        valid_results = {k: v for k, v in results.items() if v is not None}\n",
    "        \n",
    "        if valid_results:\n",
    "            # Find best by ROC AUC (primary metric)\n",
    "            best_roc = max(valid_results.items(), \n",
    "                          key=lambda x: x[1]['roc_auc'] if x[1] is not None else 0)\n",
    "            \n",
    "            # Find best by CV accuracy\n",
    "            best_cv = max(valid_results.items(), \n",
    "                         key=lambda x: x[1]['cv_mean'] if x[1] is not None else 0)\n",
    "            \n",
    "            best_models[dataset_name] = {\n",
    "                'best_roc': (best_roc[0], best_roc[1]['roc_auc']),\n",
    "                'best_cv': (best_cv[0], best_cv[1]['cv_mean'])\n",
    "            }\n",
    "    \n",
    "    return best_models\n",
    "\n",
    "best_models = find_best_model(results_summary)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BEST MODEL SELECTION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for dataset_name, bests in best_models.items():\n",
    "    print(f\"\\n{dataset_name} Dataset:\")\n",
    "    print(f\"  Best ROC AUC: {bests['best_roc'][0]} - {bests['best_roc'][1]:.3f}\")\n",
    "    print(f\"  Best CV Accuracy: {bests['best_cv'][0]} - {bests['best_cv'][1]:.3f}\")\n",
    "\n",
    "# Feature importance from best model\n",
    "best_model_name, best_model_roc = best_models['Mean_Filled']['best_roc']\n",
    "best_model = results_summary['Mean_Filled'][best_model_name]['model']\n",
    "\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_columns = [col for col in df_mean_filled.columns if col != 'optimal_modality']\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_columns,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nFeature Importance from {best_model_name}:\")\n",
    "    display(importance_df)\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=importance_df, x='importance', y='feature')\n",
    "    plt.title(f'Feature Importance - {best_model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
