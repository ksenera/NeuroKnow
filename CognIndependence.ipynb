{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b190174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NeuroKnow: AI-Powered Learning Optimization for Neurodivergent Students\n",
    "# Comprehensive Model Comparison Study\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f07f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Introduction\n",
    "print(\"\"\"\n",
    "# NeuroKnow: AI-Powered Learning Optimization for Neurodivergent Students\n",
    "## Predicting Optimal Learning Modalities Using Machine Learning\n",
    "\n",
    "**Abstract** - This study compares multiple machine learning algorithms to identify the best model \n",
    "for predicting optimal learning pathways for neurodivergent students. By analyzing cognitive profiles, \n",
    "learning patterns, and performance data, we aim to create personalized educational recommendations \n",
    "that maximize learning efficiency and knowledge retention. The project evaluates eight different \n",
    "algorithms using cross-validation and ROC-AUC analysis to determine the most effective approach \n",
    "for educational personalization.\n",
    "\n",
    "**Keywords** - neurodivergent learning, educational AI, personalized learning, cognitive profiling, \n",
    "machine learning, cross-validation, ROC analysis, modality optimization\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0756f81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Generate Synthetic Cognitive Dataset\n",
    "def generate_neurodivergent_dataset(n_samples=1000):\n",
    "    \"\"\"Generate synthetic dataset representing neurodivergent learning profiles\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    data = {\n",
    "        'age': np.random.randint(8, 18, n_samples),\n",
    "        'attention_span': np.random.normal(25, 10, n_samples),  # minutes\n",
    "        'working_memory': np.random.normal(6, 2, n_samples),    # digit span\n",
    "        'processing_speed': np.random.normal(85, 15, n_samples), # standardized score\n",
    "        'visual_learning_score': np.random.normal(70, 20, n_samples),\n",
    "        'auditory_learning_score': np.random.normal(65, 18, n_samples),\n",
    "        'kinesthetic_learning_score': np.random.normal(75, 22, n_samples),\n",
    "        'logical_reasoning_score': np.random.normal(80, 15, n_samples),\n",
    "        'error_recovery_rate': np.random.normal(0.6, 0.2, n_samples), # 0-1 scale\n",
    "        'abstraction_ability': np.random.normal(70, 18, n_samples),\n",
    "        'previous_success_rate': np.random.normal(0.7, 0.15, n_samples)\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Create target variable: optimal learning modality (0: Visual, 1: Auditory, 2: Kinesthetic, 3: Logical)\n",
    "    # Based on highest learning score with some noise\n",
    "    scores = df[['visual_learning_score', 'auditory_learning_score', \n",
    "                 'kinesthetic_learning_score', 'logical_reasoning_score']].values\n",
    "    optimal_modality = np.argmax(scores, axis=1)\n",
    "\n",
    "    # Add some realistic noise\n",
    "    noise = np.random.choice([-1, 0, 1], size=n_samples, p=[0.1, 0.8, 0.1])\n",
    "    df['optimal_modality'] = (optimal_modality + noise) % 4\n",
    "\n",
    "    # Add some missing values realistically (5% missing)\n",
    "    for col in ['working_memory', 'processing_speed', 'error_recovery_rate']:\n",
    "        mask = np.random.random(n_samples) < 0.05\n",
    "        df.loc[mask, col] = np.nan\n",
    "\n",
    "    return df\n",
    "\n",
    "# Generate and display dataset\n",
    "cognitive_df = generate_neurodivergent_dataset()\n",
    "print(\"Dataset Overview:\")\n",
    "print(f\"Shape: {cognitive_df.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(cognitive_df.head())\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "cognitive_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fbb385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Data Cleaning and Exploration\n",
    "def handle_missing_data(df, strategy='mean'):\n",
    "    \"\"\"Handle missing values using specified strategy\"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    if strategy == 'mean':\n",
    "        # Fill numerical columns with mean\n",
    "        numerical_cols = ['working_memory', 'processing_speed', 'error_recovery_rate']\n",
    "        for col in numerical_cols:\n",
    "            df_clean[col].fillna(df_clean[col].mean(), inplace=True)\n",
    "    else:  # drop\n",
    "        df_clean = df_clean.dropna()\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Create two datasets for comparison\n",
    "df_mean_filled = handle_missing_data(cognitive_df, 'mean')\n",
    "df_dropped = handle_missing_data(cognitive_df, 'drop')\n",
    "\n",
    "print(\"Dataset sizes after preprocessing:\")\n",
    "print(f\"Mean-filled: {df_mean_filled.shape}\")\n",
    "print(f\"Dropped missing: {df_dropped.shape}\")\n",
    "\n",
    "# Visualize the distribution of optimal modalities\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "modality_names = ['Visual', 'Auditory', 'Kinesthetic', 'Logical']\n",
    "df_mean_filled['optimal_modality'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('Optimal Modality Distribution (Mean-filled)')\n",
    "plt.xticks(ticks=range(4), labels=modality_names, rotation=45)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "df_dropped['optimal_modality'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('Optimal Modality Distribution (Dropped)')\n",
    "plt.xticks(ticks=range(4), labels=modality_names, rotation=45)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
